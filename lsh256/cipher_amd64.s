// Code generated by command: go run main.go -out ../cipher_amd64.s -stubs ../cipher_amd64_stubs.go. DO NOT EDIT.

#include "textflag.h"

DATA g_IV224<>+0(SB)/4, $0x068608d3
DATA g_IV224<>+4(SB)/4, $0x62d8f7a7
DATA g_IV224<>+8(SB)/4, $0xd76652ab
DATA g_IV224<>+12(SB)/4, $0x4c600a43
DATA g_IV224<>+16(SB)/4, $0xbdc40aa8
DATA g_IV224<>+20(SB)/4, $0x1eca0b68
DATA g_IV224<>+24(SB)/4, $0xda1a89be
DATA g_IV224<>+28(SB)/4, $0x3147d354
DATA g_IV224<>+32(SB)/4, $0x707eb4f9
DATA g_IV224<>+36(SB)/4, $0xf65b3862
DATA g_IV224<>+40(SB)/4, $0x6b0b2abe
DATA g_IV224<>+44(SB)/4, $0x56b8ec0a
DATA g_IV224<>+48(SB)/4, $0xcf237286
DATA g_IV224<>+52(SB)/4, $0xee0d1727
DATA g_IV224<>+56(SB)/4, $0x33636595
DATA g_IV224<>+60(SB)/4, $0x8bb8d05f
GLOBL g_IV224<>(SB), RODATA|NOPTR, $64

DATA g_IV256<>+0(SB)/4, $0x46a10f1f
DATA g_IV256<>+4(SB)/4, $0xfddce486
DATA g_IV256<>+8(SB)/4, $0xb41443a8
DATA g_IV256<>+12(SB)/4, $0x198e6b9d
DATA g_IV256<>+16(SB)/4, $0x3304388d
DATA g_IV256<>+20(SB)/4, $0xb0f5a3c7
DATA g_IV256<>+24(SB)/4, $0xb36061c4
DATA g_IV256<>+28(SB)/4, $0x7adbd553
DATA g_IV256<>+32(SB)/4, $0x105d5378
DATA g_IV256<>+36(SB)/4, $0x2f74de54
DATA g_IV256<>+40(SB)/4, $0x5c2f2d95
DATA g_IV256<>+44(SB)/4, $0xf2553fbe
DATA g_IV256<>+48(SB)/4, $0x8051357a
DATA g_IV256<>+52(SB)/4, $0x138668c8
DATA g_IV256<>+56(SB)/4, $0x47aa4484
DATA g_IV256<>+60(SB)/4, $0xe01afb41
GLOBL g_IV256<>(SB), RODATA|NOPTR, $64

DATA g_StepConstants<>+0(SB)/4, $0x917caf90
DATA g_StepConstants<>+4(SB)/4, $0x6c1b10a2
DATA g_StepConstants<>+8(SB)/4, $0x6f352943
DATA g_StepConstants<>+12(SB)/4, $0xcf778243
DATA g_StepConstants<>+16(SB)/4, $0x2ceb7472
DATA g_StepConstants<>+20(SB)/4, $0x29e96ff2
DATA g_StepConstants<>+24(SB)/4, $0x8a9ba428
DATA g_StepConstants<>+28(SB)/4, $0x2eeb2642
DATA g_StepConstants<>+32(SB)/4, $0x0e2c4021
DATA g_StepConstants<>+36(SB)/4, $0x872bb30e
DATA g_StepConstants<>+40(SB)/4, $0xa45e6cb2
DATA g_StepConstants<>+44(SB)/4, $0x46f9c612
DATA g_StepConstants<>+48(SB)/4, $0x185fe69e
DATA g_StepConstants<>+52(SB)/4, $0x1359621b
DATA g_StepConstants<>+56(SB)/4, $0x263fccb2
DATA g_StepConstants<>+60(SB)/4, $0x1a116870
DATA g_StepConstants<>+64(SB)/4, $0x3a6c612f
DATA g_StepConstants<>+68(SB)/4, $0xb2dec195
DATA g_StepConstants<>+72(SB)/4, $0x02cb1f56
DATA g_StepConstants<>+76(SB)/4, $0x40bfd858
DATA g_StepConstants<>+80(SB)/4, $0x784684b6
DATA g_StepConstants<>+84(SB)/4, $0x6cbb7d2e
DATA g_StepConstants<>+88(SB)/4, $0x660c7ed8
DATA g_StepConstants<>+92(SB)/4, $0x2b79d88a
DATA g_StepConstants<>+96(SB)/4, $0xa6cd9069
DATA g_StepConstants<>+100(SB)/4, $0x91a05747
DATA g_StepConstants<>+104(SB)/4, $0xcdea7558
DATA g_StepConstants<>+108(SB)/4, $0x00983098
DATA g_StepConstants<>+112(SB)/4, $0xbecb3b2e
DATA g_StepConstants<>+116(SB)/4, $0x2838ab9a
DATA g_StepConstants<>+120(SB)/4, $0x728b573e
DATA g_StepConstants<>+124(SB)/4, $0xa55262b5
DATA g_StepConstants<>+128(SB)/4, $0x745dfa0f
DATA g_StepConstants<>+132(SB)/4, $0x31f79ed8
DATA g_StepConstants<>+136(SB)/4, $0xb85fce25
DATA g_StepConstants<>+140(SB)/4, $0x98c8c898
DATA g_StepConstants<>+144(SB)/4, $0x8a0669ec
DATA g_StepConstants<>+148(SB)/4, $0x60e445c2
DATA g_StepConstants<>+152(SB)/4, $0xfde295b0
DATA g_StepConstants<>+156(SB)/4, $0xf7b5185a
DATA g_StepConstants<>+160(SB)/4, $0xd2580983
DATA g_StepConstants<>+164(SB)/4, $0x29967709
DATA g_StepConstants<>+168(SB)/4, $0x182df3dd
DATA g_StepConstants<>+172(SB)/4, $0x61916130
DATA g_StepConstants<>+176(SB)/4, $0x90705676
DATA g_StepConstants<>+180(SB)/4, $0x452a0822
DATA g_StepConstants<>+184(SB)/4, $0xe07846ad
DATA g_StepConstants<>+188(SB)/4, $0xaccd7351
DATA g_StepConstants<>+192(SB)/4, $0x2a618d55
DATA g_StepConstants<>+196(SB)/4, $0xc00d8032
DATA g_StepConstants<>+200(SB)/4, $0x4621d0f5
DATA g_StepConstants<>+204(SB)/4, $0xf2f29191
DATA g_StepConstants<>+208(SB)/4, $0x00c6cd06
DATA g_StepConstants<>+212(SB)/4, $0x6f322a67
DATA g_StepConstants<>+216(SB)/4, $0x58bef48d
DATA g_StepConstants<>+220(SB)/4, $0x7a40c4fd
DATA g_StepConstants<>+224(SB)/4, $0x8beee27f
DATA g_StepConstants<>+228(SB)/4, $0xcd8db2f2
DATA g_StepConstants<>+232(SB)/4, $0x67f2c63b
DATA g_StepConstants<>+236(SB)/4, $0xe5842383
DATA g_StepConstants<>+240(SB)/4, $0xc793d306
DATA g_StepConstants<>+244(SB)/4, $0xa15c91d6
DATA g_StepConstants<>+248(SB)/4, $0x17b381e5
DATA g_StepConstants<>+252(SB)/4, $0xbb05c277
DATA g_StepConstants<>+256(SB)/4, $0x7ad1620a
DATA g_StepConstants<>+260(SB)/4, $0x5b40a5bf
DATA g_StepConstants<>+264(SB)/4, $0x5ab901a2
DATA g_StepConstants<>+268(SB)/4, $0x69a7a768
DATA g_StepConstants<>+272(SB)/4, $0x5b66d9cd
DATA g_StepConstants<>+276(SB)/4, $0xfdee6877
DATA g_StepConstants<>+280(SB)/4, $0xcb3566fc
DATA g_StepConstants<>+284(SB)/4, $0xc0c83a32
DATA g_StepConstants<>+288(SB)/4, $0x4c336c84
DATA g_StepConstants<>+292(SB)/4, $0x9be6651a
DATA g_StepConstants<>+296(SB)/4, $0x13baa3fc
DATA g_StepConstants<>+300(SB)/4, $0x114f0fd1
DATA g_StepConstants<>+304(SB)/4, $0xc240a728
DATA g_StepConstants<>+308(SB)/4, $0xec56e074
DATA g_StepConstants<>+312(SB)/4, $0x009c63c7
DATA g_StepConstants<>+316(SB)/4, $0x89026cf2
DATA g_StepConstants<>+320(SB)/4, $0x7f9ff0d0
DATA g_StepConstants<>+324(SB)/4, $0x824b7fb5
DATA g_StepConstants<>+328(SB)/4, $0xce5ea00f
DATA g_StepConstants<>+332(SB)/4, $0x605ee0e2
DATA g_StepConstants<>+336(SB)/4, $0x02e7cfea
DATA g_StepConstants<>+340(SB)/4, $0x43375560
DATA g_StepConstants<>+344(SB)/4, $0x9d002ac7
DATA g_StepConstants<>+348(SB)/4, $0x8b6f5f7b
DATA g_StepConstants<>+352(SB)/4, $0x1f90c14f
DATA g_StepConstants<>+356(SB)/4, $0xcdcb3537
DATA g_StepConstants<>+360(SB)/4, $0x2cfeafdd
DATA g_StepConstants<>+364(SB)/4, $0xbf3fc342
DATA g_StepConstants<>+368(SB)/4, $0xeab7b9ec
DATA g_StepConstants<>+372(SB)/4, $0x7a8cb5a3
DATA g_StepConstants<>+376(SB)/4, $0x9d2af264
DATA g_StepConstants<>+380(SB)/4, $0xfacedb06
DATA g_StepConstants<>+384(SB)/4, $0xb052106e
DATA g_StepConstants<>+388(SB)/4, $0x99006d04
DATA g_StepConstants<>+392(SB)/4, $0x2bae8d09
DATA g_StepConstants<>+396(SB)/4, $0xff030601
DATA g_StepConstants<>+400(SB)/4, $0xa271a6d6
DATA g_StepConstants<>+404(SB)/4, $0x0742591d
DATA g_StepConstants<>+408(SB)/4, $0xc81d5701
DATA g_StepConstants<>+412(SB)/4, $0xc9a9e200
DATA g_StepConstants<>+416(SB)/4, $0x02627f1e
DATA g_StepConstants<>+420(SB)/4, $0x996d719d
DATA g_StepConstants<>+424(SB)/4, $0xda3b9634
DATA g_StepConstants<>+428(SB)/4, $0x02090800
DATA g_StepConstants<>+432(SB)/4, $0x14187d78
DATA g_StepConstants<>+436(SB)/4, $0x499b7624
DATA g_StepConstants<>+440(SB)/4, $0xe57458c9
DATA g_StepConstants<>+444(SB)/4, $0x738be2c9
DATA g_StepConstants<>+448(SB)/4, $0x64e19d20
DATA g_StepConstants<>+452(SB)/4, $0x06df0f36
DATA g_StepConstants<>+456(SB)/4, $0x15d1cb0e
DATA g_StepConstants<>+460(SB)/4, $0x0b110802
DATA g_StepConstants<>+464(SB)/4, $0x2c95f58c
DATA g_StepConstants<>+468(SB)/4, $0xe5119a6d
DATA g_StepConstants<>+472(SB)/4, $0x59cd22ae
DATA g_StepConstants<>+476(SB)/4, $0xff6eac3c
DATA g_StepConstants<>+480(SB)/4, $0x467ebd84
DATA g_StepConstants<>+484(SB)/4, $0xe5ee453c
DATA g_StepConstants<>+488(SB)/4, $0xe79cd923
DATA g_StepConstants<>+492(SB)/4, $0x1c190a0d
DATA g_StepConstants<>+496(SB)/4, $0xc28b81b8
DATA g_StepConstants<>+500(SB)/4, $0xf6ac0852
DATA g_StepConstants<>+504(SB)/4, $0x26efd107
DATA g_StepConstants<>+508(SB)/4, $0x6e1ae93b
DATA g_StepConstants<>+512(SB)/4, $0xc53c41ca
DATA g_StepConstants<>+516(SB)/4, $0xd4338221
DATA g_StepConstants<>+520(SB)/4, $0x8475fd0a
DATA g_StepConstants<>+524(SB)/4, $0x35231729
DATA g_StepConstants<>+528(SB)/4, $0x4e0d3a7a
DATA g_StepConstants<>+532(SB)/4, $0xa2b45b48
DATA g_StepConstants<>+536(SB)/4, $0x16c0d82d
DATA g_StepConstants<>+540(SB)/4, $0x890424a9
DATA g_StepConstants<>+544(SB)/4, $0x017e0c8f
DATA g_StepConstants<>+548(SB)/4, $0x07b5a3f5
DATA g_StepConstants<>+552(SB)/4, $0xfa73078e
DATA g_StepConstants<>+556(SB)/4, $0x583a405e
DATA g_StepConstants<>+560(SB)/4, $0x5b47b4c8
DATA g_StepConstants<>+564(SB)/4, $0x570fa3ea
DATA g_StepConstants<>+568(SB)/4, $0xd7990543
DATA g_StepConstants<>+572(SB)/4, $0x8d28ce32
DATA g_StepConstants<>+576(SB)/4, $0x7f8a9b90
DATA g_StepConstants<>+580(SB)/4, $0xbd5998fc
DATA g_StepConstants<>+584(SB)/4, $0x6d7a9688
DATA g_StepConstants<>+588(SB)/4, $0x927a9eb6
DATA g_StepConstants<>+592(SB)/4, $0xa2fc7d23
DATA g_StepConstants<>+596(SB)/4, $0x66b38e41
DATA g_StepConstants<>+600(SB)/4, $0x709e491a
DATA g_StepConstants<>+604(SB)/4, $0xb5f700bf
DATA g_StepConstants<>+608(SB)/4, $0x0a262c0f
DATA g_StepConstants<>+612(SB)/4, $0x16f295b9
DATA g_StepConstants<>+616(SB)/4, $0xe8111ef5
DATA g_StepConstants<>+620(SB)/4, $0x0d195548
DATA g_StepConstants<>+624(SB)/4, $0x9f79a0c5
DATA g_StepConstants<>+628(SB)/4, $0x1a41cfa7
DATA g_StepConstants<>+632(SB)/4, $0x0ee7638a
DATA g_StepConstants<>+636(SB)/4, $0xacf7c074
DATA g_StepConstants<>+640(SB)/4, $0x30523b19
DATA g_StepConstants<>+644(SB)/4, $0x09884ecf
DATA g_StepConstants<>+648(SB)/4, $0xf93014dd
DATA g_StepConstants<>+652(SB)/4, $0x266e9d55
DATA g_StepConstants<>+656(SB)/4, $0x191a6664
DATA g_StepConstants<>+660(SB)/4, $0x5c1176c1
DATA g_StepConstants<>+664(SB)/4, $0xf64aed98
DATA g_StepConstants<>+668(SB)/4, $0xa4b83520
DATA g_StepConstants<>+672(SB)/4, $0x828d5449
DATA g_StepConstants<>+676(SB)/4, $0x91d71dd8
DATA g_StepConstants<>+680(SB)/4, $0x2944f2d6
DATA g_StepConstants<>+684(SB)/4, $0x950bf27b
DATA g_StepConstants<>+688(SB)/4, $0x3380ca7d
DATA g_StepConstants<>+692(SB)/4, $0x6d88381d
DATA g_StepConstants<>+696(SB)/4, $0x4138868e
DATA g_StepConstants<>+700(SB)/4, $0x5ced55c4
DATA g_StepConstants<>+704(SB)/4, $0x0fe19dcb
DATA g_StepConstants<>+708(SB)/4, $0x68f4f669
DATA g_StepConstants<>+712(SB)/4, $0x6e37c8ff
DATA g_StepConstants<>+716(SB)/4, $0xa0fe6e10
DATA g_StepConstants<>+720(SB)/4, $0xb44b47b0
DATA g_StepConstants<>+724(SB)/4, $0xf5c0558a
DATA g_StepConstants<>+728(SB)/4, $0x79bf14cf
DATA g_StepConstants<>+732(SB)/4, $0x4a431a20
DATA g_StepConstants<>+736(SB)/4, $0xf17f68da
DATA g_StepConstants<>+740(SB)/4, $0x5deb5fd1
DATA g_StepConstants<>+744(SB)/4, $0xa600c86d
DATA g_StepConstants<>+748(SB)/4, $0x9f6c7eb0
DATA g_StepConstants<>+752(SB)/4, $0xff92f864
DATA g_StepConstants<>+756(SB)/4, $0xb615e07f
DATA g_StepConstants<>+760(SB)/4, $0x38d3e448
DATA g_StepConstants<>+764(SB)/4, $0x8d5d3a6a
DATA g_StepConstants<>+768(SB)/4, $0x70e843cb
DATA g_StepConstants<>+772(SB)/4, $0x494b312e
DATA g_StepConstants<>+776(SB)/4, $0xa6c93613
DATA g_StepConstants<>+780(SB)/4, $0x0beb2f4f
DATA g_StepConstants<>+784(SB)/4, $0x928b5d63
DATA g_StepConstants<>+788(SB)/4, $0xcbf66035
DATA g_StepConstants<>+792(SB)/4, $0x0cb82c80
DATA g_StepConstants<>+796(SB)/4, $0xea97a4f7
DATA g_StepConstants<>+800(SB)/4, $0x592c0f3b
DATA g_StepConstants<>+804(SB)/4, $0x947c5f77
DATA g_StepConstants<>+808(SB)/4, $0x6fff49b9
DATA g_StepConstants<>+812(SB)/4, $0xf71a7e5a
DATA g_StepConstants<>+816(SB)/4, $0x1de8c0f5
DATA g_StepConstants<>+820(SB)/4, $0xc2569600
DATA g_StepConstants<>+824(SB)/4, $0xc4e4ac8c
DATA g_StepConstants<>+828(SB)/4, $0x823c9ce1
GLOBL g_StepConstants<>(SB), RODATA|NOPTR, $832

DATA g_BytePermInfo_L_sse2_0<>+0(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_0<>+4(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_0<>+8(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_0<>+12(SB)/4, $0x00000000
GLOBL g_BytePermInfo_L_sse2_0<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_L_sse2_1<>+0(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_1<>+4(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_1<>+8(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_1<>+12(SB)/4, $0xffffffff
GLOBL g_BytePermInfo_L_sse2_1<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_L_sse2_2<>+0(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_2<>+4(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_2<>+8(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_2<>+12(SB)/4, $0x00000000
GLOBL g_BytePermInfo_L_sse2_2<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_L_sse2_3<>+0(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_3<>+4(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_3<>+8(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_3<>+12(SB)/4, $0xffffffff
GLOBL g_BytePermInfo_L_sse2_3<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_L_sse2_4<>+0(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_4<>+4(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_4<>+8(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_4<>+12(SB)/4, $0x00000000
GLOBL g_BytePermInfo_L_sse2_4<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_L_sse2_5<>+0(SB)/4, $0x00000000
DATA g_BytePermInfo_L_sse2_5<>+4(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_5<>+8(SB)/4, $0xffffffff
DATA g_BytePermInfo_L_sse2_5<>+12(SB)/4, $0xffffffff
GLOBL g_BytePermInfo_L_sse2_5<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_R_sse2_0<>+0(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_0<>+4(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_0<>+8(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_0<>+12(SB)/4, $0xffffffff
GLOBL g_BytePermInfo_R_sse2_0<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_R_sse2_1<>+0(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_1<>+4(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_1<>+8(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_1<>+12(SB)/4, $0x00000000
GLOBL g_BytePermInfo_R_sse2_1<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_R_sse2_2<>+0(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_2<>+4(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_2<>+8(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_2<>+12(SB)/4, $0xffffffff
GLOBL g_BytePermInfo_R_sse2_2<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_R_sse2_3<>+0(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_3<>+4(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_3<>+8(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_3<>+12(SB)/4, $0x00000000
GLOBL g_BytePermInfo_R_sse2_3<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_R_sse2_4<>+0(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_4<>+4(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_4<>+8(SB)/4, $0x00000000
DATA g_BytePermInfo_R_sse2_4<>+12(SB)/4, $0xffffffff
GLOBL g_BytePermInfo_R_sse2_4<>(SB), RODATA|NOPTR, $16

DATA g_BytePermInfo_R_sse2_5<>+0(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_5<>+4(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_5<>+8(SB)/4, $0xffffffff
DATA g_BytePermInfo_R_sse2_5<>+12(SB)/4, $0x00000000
GLOBL g_BytePermInfo_R_sse2_5<>(SB), RODATA|NOPTR, $16

// func lsh256InitSSE2(ctx *lsh256ContextAsmData)
// Requires: SSE, SSE2
TEXT ·lsh256InitSSE2(SB), NOSPLIT, $0-8
	MOVQ   ctx+0(FP), AX
	MOVQ   (AX), CX
	MOVQ   16(AX), DX
	MOVQ   40(AX), AX
	CMPQ   CX, $0x00000020
	JNE    not_256
	MOVO   g_IV256<>+0(SB), X0
	MOVAPS X0, (DX)
	MOVO   g_IV256<>+16(SB), X0
	MOVAPS X0, 16(DX)
	MOVO   g_IV256<>+32(SB), X0
	MOVAPS X0, (AX)
	MOVO   g_IV256<>+48(SB), X0
	MOVAPS X0, 16(AX)
	JMP    ret

not_256:
	MOVO   g_IV224<>+0(SB), X0
	MOVAPS X0, (DX)
	MOVO   g_IV224<>+16(SB), X0
	MOVAPS X0, 16(DX)
	MOVO   g_IV224<>+32(SB), X0
	MOVAPS X0, (AX)
	MOVO   g_IV224<>+48(SB), X0
	MOVAPS X0, 16(AX)

ret:
	RET

// func lsh256UpdateSSE2(ctx *lsh256ContextAsmData, data []byte, remain_msg_byte int) int
// Requires: SSE2
TEXT ·lsh256UpdateSSE2(SB), NOSPLIT, $0-48
	// return databytelen
	MOVQ ctx+0(FP), AX
	MOVQ 8(AX), CX
	MOVQ 16(AX), DX
	MOVQ 40(AX), BX
	MOVQ 64(AX), CX
	MOVQ data_base+8(FP), AX
	MOVQ data_len+16(FP), SI
	MOVQ remain_msg_byte+32(FP), DI

	// load_blk
	MOVOU (DX), X0
	MOVOU 16(DX), X1

	// load_blk
	MOVOU (BX), X2
	MOVOU 16(BX), X3
	CMPQ  DI, $0x00000000
	JLE   end_if1
	MOVQ  $0x0000000000000080, R8
	SUBQ  DI, R8

	// compress
	// load_msg_blk
	// load_blk
	MOVOU (CX), X4
	MOVOU 16(CX), X5

	// load_blk
	MOVOU 32(CX), X6
	MOVOU 48(CX), X7

	// load_blk
	MOVOU 64(CX), X8
	MOVOU 80(CX), X9

	// load_blk
	MOVOU 96(CX), X10
	MOVOU 112(CX), X11

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+0(SB), X0
	PXOR g_StepConstants<>+16(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+32(SB), X1
	PXOR g_StepConstants<>+48(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+64(SB), X3
	PXOR g_StepConstants<>+80(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+96(SB), X2
	PXOR g_StepConstants<>+112(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+128(SB), X0
	PXOR g_StepConstants<>+144(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+160(SB), X1
	PXOR g_StepConstants<>+176(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+192(SB), X3
	PXOR g_StepConstants<>+208(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+224(SB), X2
	PXOR g_StepConstants<>+240(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+256(SB), X0
	PXOR g_StepConstants<>+272(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+288(SB), X1
	PXOR g_StepConstants<>+304(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+320(SB), X3
	PXOR g_StepConstants<>+336(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+352(SB), X2
	PXOR g_StepConstants<>+368(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+384(SB), X0
	PXOR g_StepConstants<>+400(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+416(SB), X1
	PXOR g_StepConstants<>+432(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+448(SB), X3
	PXOR g_StepConstants<>+464(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+480(SB), X2
	PXOR g_StepConstants<>+496(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+512(SB), X0
	PXOR g_StepConstants<>+528(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+544(SB), X1
	PXOR g_StepConstants<>+560(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+576(SB), X3
	PXOR g_StepConstants<>+592(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+608(SB), X2
	PXOR g_StepConstants<>+624(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+640(SB), X0
	PXOR g_StepConstants<>+656(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+672(SB), X1
	PXOR g_StepConstants<>+688(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+704(SB), X3
	PXOR g_StepConstants<>+720(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+736(SB), X2
	PXOR g_StepConstants<>+752(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+768(SB), X0
	PXOR g_StepConstants<>+784(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+800(SB), X1
	PXOR g_StepConstants<>+816(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// data += more_byte;
	ADDQ R8, AX
	SUBQ R8, SI
	MOVQ $0x0000000000000000, DI
	MOVQ $0x0000000000000000, CX

end_if1:
while_0_loop:
	CMPQ SI, $0x00000080
	JL   while_0_done

	// compress
	// load_msg_blk
	// load_blk
	MOVOU (AX), X4
	MOVOU 16(AX), X5

	// load_blk
	MOVOU 32(AX), X6
	MOVOU 48(AX), X7

	// load_blk
	MOVOU 64(AX), X8
	MOVOU 80(AX), X9

	// load_blk
	MOVOU 96(AX), X10
	MOVOU 112(AX), X11

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+0(SB), X3
	PXOR g_StepConstants<>+16(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+32(SB), X2
	PXOR g_StepConstants<>+48(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+64(SB), X0
	PXOR g_StepConstants<>+80(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+96(SB), X1
	PXOR g_StepConstants<>+112(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+128(SB), X3
	PXOR g_StepConstants<>+144(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+160(SB), X2
	PXOR g_StepConstants<>+176(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+192(SB), X0
	PXOR g_StepConstants<>+208(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+224(SB), X1
	PXOR g_StepConstants<>+240(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+256(SB), X3
	PXOR g_StepConstants<>+272(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+288(SB), X2
	PXOR g_StepConstants<>+304(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+320(SB), X0
	PXOR g_StepConstants<>+336(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+352(SB), X1
	PXOR g_StepConstants<>+368(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+384(SB), X3
	PXOR g_StepConstants<>+400(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+416(SB), X2
	PXOR g_StepConstants<>+432(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+448(SB), X0
	PXOR g_StepConstants<>+464(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+480(SB), X1
	PXOR g_StepConstants<>+496(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+512(SB), X3
	PXOR g_StepConstants<>+528(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+544(SB), X2
	PXOR g_StepConstants<>+560(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+576(SB), X0
	PXOR g_StepConstants<>+592(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+608(SB), X1
	PXOR g_StepConstants<>+624(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+640(SB), X3
	PXOR g_StepConstants<>+656(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+672(SB), X2
	PXOR g_StepConstants<>+688(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+704(SB), X0
	PXOR g_StepConstants<>+720(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+736(SB), X1
	PXOR g_StepConstants<>+752(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+768(SB), X3
	PXOR g_StepConstants<>+784(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+800(SB), X2
	PXOR g_StepConstants<>+816(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// data += LSH256_MSG_BLK_BYTE_LEN
	ADDQ $0x00000080, AX
	SUBQ $0x80, SI
	JMP  while_0_loop

while_0_done:
	// store_blk
	MOVOU X0, (DX)
	MOVOU X1, 16(DX)

	// store_blk
	MOVOU X2, (BX)
	MOVOU X3, 16(BX)

	// return value
	MOVQ SI, ret+40(FP)
	RET

// func lsh256FinalSSE2(ctx *lsh256ContextAsmData, hashval []byte)
// Requires: SSE2
TEXT ·lsh256FinalSSE2(SB), NOSPLIT, $0-32
	MOVQ ctx+0(FP), AX
	MOVQ (AX), CX
	MOVQ 16(AX), DX
	MOVQ 40(AX), BX
	MOVQ 64(AX), AX
	MOVQ hashval_base+8(FP), SI

	// load_blk
	MOVOU (DX), X0
	MOVOU 16(DX), X1

	// load_blk
	MOVOU (BX), X2
	MOVOU 16(BX), X3

	// compress
	// load_msg_blk
	// load_blk
	MOVOU (AX), X4
	MOVOU 16(AX), X5

	// load_blk
	MOVOU 32(AX), X6
	MOVOU 48(AX), X7

	// load_blk
	MOVOU 64(AX), X8
	MOVOU 80(AX), X9

	// load_blk
	MOVOU 96(AX), X10
	MOVOU 112(AX), X11

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+0(SB), X0
	PXOR g_StepConstants<>+16(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+32(SB), X1
	PXOR g_StepConstants<>+48(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+64(SB), X3
	PXOR g_StepConstants<>+80(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+96(SB), X2
	PXOR g_StepConstants<>+112(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+128(SB), X0
	PXOR g_StepConstants<>+144(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+160(SB), X1
	PXOR g_StepConstants<>+176(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+192(SB), X3
	PXOR g_StepConstants<>+208(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+224(SB), X2
	PXOR g_StepConstants<>+240(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+256(SB), X0
	PXOR g_StepConstants<>+272(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+288(SB), X1
	PXOR g_StepConstants<>+304(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+320(SB), X3
	PXOR g_StepConstants<>+336(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+352(SB), X2
	PXOR g_StepConstants<>+368(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+384(SB), X0
	PXOR g_StepConstants<>+400(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+416(SB), X1
	PXOR g_StepConstants<>+432(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+448(SB), X3
	PXOR g_StepConstants<>+464(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+480(SB), X2
	PXOR g_StepConstants<>+496(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+512(SB), X0
	PXOR g_StepConstants<>+528(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+544(SB), X1
	PXOR g_StepConstants<>+560(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+576(SB), X3
	PXOR g_StepConstants<>+592(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+608(SB), X2
	PXOR g_StepConstants<>+624(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+640(SB), X0
	PXOR g_StepConstants<>+656(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+672(SB), X1
	PXOR g_StepConstants<>+688(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// mix_even
	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_blk_even_alpha
	MOVO  X3, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X3
	POR   X12, X3
	MOVO  X2, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X2
	POR   X12, X2

	// xor_with_const
	PXOR g_StepConstants<>+704(SB), X3
	PXOR g_StepConstants<>+720(SB), X2

	// add_blk
	PADDD X3, X1
	PADDD X2, X0

	// rotate_blk_even_beta
	MOVO  X1, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X1
	POR   X12, X1
	MOVO  X0, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X0
	POR   X12, X0

	// add_blk
	PADDD X1, X3
	PADDD X0, X2

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0

	// word_perm
	PSHUFD $0xd2, X3, X3
	PSHUFD $0xd2, X2, X2
	PSHUFD $0x6c, X1, X1
	PSHUFD $0x6c, X0, X0

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X2
	PXOR X10, X3
	PXOR X9, X0
	PXOR X11, X1

	// mix_odd
	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_blk_odd_alpha
	MOVO  X2, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X2
	POR   X12, X2
	MOVO  X0, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X0
	POR   X12, X0

	// xor_with_const
	PXOR g_StepConstants<>+736(SB), X2
	PXOR g_StepConstants<>+752(SB), X0

	// add_blk
	PADDD X2, X3
	PADDD X0, X1

	// rotate_blk_odd_beta
	MOVO  X3, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X3
	POR   X12, X3
	MOVO  X1, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X1
	POR   X12, X1

	// add_blk
	PADDD X3, X2
	PADDD X1, X0

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X1, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X1
	PAND  X12, X1
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X1, X13
	PSLLL $0x08, X1
	PSRLL $0x18, X13
	PXOR  X13, X1
	PXOR  X12, X1
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X1, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X1
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X1

	// word_perm
	PSHUFD $0xd2, X2, X2
	PSHUFD $0xd2, X0, X0
	PSHUFD $0x6c, X3, X3
	PSHUFD $0x6c, X1, X1

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X0
	PXOR X6, X2
	PXOR X5, X1
	PXOR X7, X3

	// mix_even
	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_blk_even_alpha
	MOVO  X0, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X0
	POR   X12, X0
	MOVO  X1, X12
	PSLLL $0x1d, X12
	PSRLL $0x03, X1
	POR   X12, X1

	// xor_with_const
	PXOR g_StepConstants<>+768(SB), X0
	PXOR g_StepConstants<>+784(SB), X1

	// add_blk
	PADDD X0, X2
	PADDD X1, X3

	// rotate_blk_even_beta
	MOVO  X2, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X2
	POR   X12, X2
	MOVO  X3, X12
	PSLLL $0x01, X12
	PSRLL $0x1f, X3
	POR   X12, X3

	// add_blk
	PADDD X2, X0
	PADDD X3, X1

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X3, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X3
	PAND  X12, X3
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X3, X13
	PSLLL $0x08, X3
	PSRLL $0x18, X13
	PXOR  X13, X3
	PXOR  X12, X3
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X3, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X3
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X3

	// word_perm
	PSHUFD $0xd2, X0, X0
	PSHUFD $0xd2, X1, X1
	PSHUFD $0x6c, X2, X2
	PSHUFD $0x6c, X3, X3

	// msg_exp_odd
	PSHUFD $0x4b, X8, X8
	PAND   X4, X8
	PSHUFD $0x93, X9, X9
	PAND   X5, X9
	PSHUFD $0x4b, X10, X10
	PAND   X6, X10
	PSHUFD $0x93, X11, X11
	PAND   X7, X11

	// msg_add_odd
	PXOR X8, X1
	PXOR X10, X0
	PXOR X9, X3
	PXOR X11, X2

	// mix_odd
	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_blk_odd_alpha
	MOVO  X1, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X1
	POR   X12, X1
	MOVO  X3, X12
	PSLLL $0x05, X12
	PSRLL $0x1b, X3
	POR   X12, X3

	// xor_with_const
	PXOR g_StepConstants<>+800(SB), X1
	PXOR g_StepConstants<>+816(SB), X3

	// add_blk
	PADDD X1, X0
	PADDD X3, X2

	// rotate_blk_odd_beta
	MOVO  X0, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X0
	POR   X12, X0
	MOVO  X2, X12
	PSLLL $0x11, X12
	PSRLL $0x0f, X2
	POR   X12, X2

	// add_blk
	PADDD X0, X1
	PADDD X2, X3

	// rotate_msg_gamma
	MOVO  g_BytePermInfo_L_sse2_0<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_1<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X0, X12
	MOVO  g_BytePermInfo_L_sse2_2<>+0(SB), X0
	PAND  X12, X0
	PAND  g_BytePermInfo_L_sse2_3<>+0(SB), X12
	MOVO  X0, X13
	PSLLL $0x08, X0
	PSRLL $0x18, X13
	PXOR  X13, X0
	PXOR  X12, X0
	MOVO  g_BytePermInfo_L_sse2_4<>+0(SB), X12
	PAND  X0, X12
	PAND  g_BytePermInfo_L_sse2_5<>+0(SB), X0
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X0
	MOVO  g_BytePermInfo_R_sse2_0<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_1<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X2, X12
	MOVO  g_BytePermInfo_R_sse2_2<>+0(SB), X2
	PAND  X12, X2
	PAND  g_BytePermInfo_R_sse2_3<>+0(SB), X12
	MOVO  X2, X13
	PSLLL $0x08, X2
	PSRLL $0x18, X13
	PXOR  X13, X2
	PXOR  X12, X2
	MOVO  g_BytePermInfo_R_sse2_4<>+0(SB), X12
	PAND  X2, X12
	PAND  g_BytePermInfo_R_sse2_5<>+0(SB), X2
	MOVO  X12, X13
	PSLLL $0x08, X12
	PSRLL $0x18, X13
	PXOR  X13, X12
	PXOR  X12, X2

	// word_perm
	PSHUFD $0xd2, X1, X1
	PSHUFD $0xd2, X3, X3
	PSHUFD $0x6c, X0, X0
	PSHUFD $0x6c, X2, X2

	// msg_exp_even
	PSHUFD $0x4b, X4, X4
	PAND   X8, X4
	PSHUFD $0x93, X5, X5
	PAND   X9, X5
	PSHUFD $0x4b, X6, X6
	PAND   X10, X6
	PSHUFD $0x93, X7, X7
	PAND   X11, X7

	// msg_add_even
	PXOR X4, X3
	PXOR X6, X1
	PXOR X5, X2
	PXOR X7, X0

	// fin
	PXOR X1, X3
	PXOR X0, X2

	// get_hash
	MOVQ  CX, AX
	ANDQ  $0x0000ffff, AX
	MOVOU X3, (SI)
	MOVOU X2, 16(SI)
	RET
